{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import base64\n",
    "import requests\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"DataSet/train\" # กำหนด path เพื่อเข้าไปดึงข้อมูลรูปภาพ\n",
    "list_x = []\n",
    "list_y = []\n",
    "\n",
    "for sub in os.listdir(path): # ดึงรูปภาพมาเก็บไว้ใน list_x และชื่อโฟลเดอร์มาเก็บใน list_y\n",
    "    for fn in os.listdir(os.path.join(path, sub)):\n",
    "        path_file_img = os.path.join(path, sub, fn)\n",
    "        readImage = cv2.imread(path_file_img, cv2.IMREAD_GRAYSCALE)\n",
    "        list_x.append(readImage)\n",
    "        list_y.append(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgtovec(img): # สร้าง function ขึ้นมาเพื่อเรียกใช้ api ที่สร้างไว้\n",
    "    try:\n",
    "        resized_img = cv2.resize(img, (128, 128), cv2.INTER_AREA)\n",
    "        v, buffer = cv2.imencode(\".jpg\", resized_img)\n",
    "        img_str = base64.b64encode(buffer).decode('utf-8')\n",
    "        image_data_string = img_str\n",
    "\n",
    "        url = \"http://localhost:80/api/genhog\"\n",
    "        params = {\"img\": image_data_string}\n",
    "\n",
    "        response = requests.get(url, json=params)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            return {\"error\": f\"เรียก API ไม่สำเร็จ : {response.status_code}\"}\n",
    "    except Exception as ex:\n",
    "        return {\"error\": f\"เกิดข้อผิดพลาด: {str(ex)}\"}\n",
    "\n",
    "# เรียกใช้ api จะได้ข้อมูลภาพที่เป็น hog มาและเก็บใน hogvector\n",
    "hogvectors = []\n",
    "for i in range(len(list_x)):\n",
    "    res = imgtovec(list_x[i])\n",
    "    vec = list(res[\"hog\"])\n",
    "    vec.append(list_y[i])\n",
    "    hogvectors.append(vec)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data preparation is done\n"
     ]
    }
   ],
   "source": [
    "# เขียน hogvectors_train.pkl ขึ้นมา\n",
    "write_path = \"hogvectors_train.pkl\"\n",
    "pickle.dump(hogvectors, open(write_path, \"wb\"))\n",
    "print(\"data preparation is done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "hogvectors_train = pickle.load(open('hogvectors_train.pkl', 'rb'))\n",
    "hogvectors_test = pickle.load(open('hogvectors_test.pkl', 'rb'))\n",
    "\n",
    "# ดึงข้อมูลทุกแถว และ คอลัมน์ที่ 0-8099 มาเป็น feature \n",
    "X_train_data = [hogfeature_Xtrain[0:8100] for hogfeature_Xtrain in hogvectors_train]\n",
    "X_test_data = [hogfeature_Xtest[0:8100] for hogfeature_Xtest in hogvectors_test]\n",
    "\n",
    "# ดึงข้อมูลทุกแถว แต่เอาแค่คอลัมน์สุดท้าย มาเป็น class\n",
    "Y_train_data = [hogfeature_Ytrain[-1] for hogfeature_Ytrain in hogvectors_train]\n",
    "Y_test_data = [hogfeature_Ytest[-1] for hogfeature_Ytest in hogvectors_test]\n",
    "\n",
    "label_encoder = LabelEncoder() # สร้าง object label_encoder จาก Class LabelEncoder เพราะต้องใช้ในการแปลงชื่อยี่ห้อรถยนต์เป็นตัวเลข\n",
    "y_cls_train = label_encoder.fit(Y_train_data) # ใช้ .fit(Y_train_data) เพื่อใช้ในการเรียนรู้ว่า ชื่อยี่ห้อรถยนต์จะถูกแทนด้วยตัวเลขอะไรบ้าง ( ทำ mapping )\n",
    "y_labelNum_train = label_encoder.transform(Y_train_data) # หลังจากใช้ .fit เพื่ออบรมแล้วจะเป็นตัวเลขตาม mapping ที่ถูกสร้างไว้\n",
    "y_cls_test = label_encoder.fit(Y_test_data)\n",
    "y_labelNum_test = label_encoder.transform(Y_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# สร้าง object จาก model DecisionTree\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# สร้าง object จาก modelXGBoost\n",
    "xgb_model = xgb.XGBClassifier(objective=\"multi:softmax\",num_class=len(label_encoder.classes_), random_state=42)\n",
    "\n",
    "# ทำการรวม 2โมเดล ที่สร้างไว้มารวมด้วยกัน \n",
    "ensemble_model = VotingClassifier(estimators=[('DecisionTree', clf), ('XGBoost', xgb_model)], voting='hard',weights=[1, 4])\n",
    "\n",
    "# .fit() X_train_data เป็นการให้โมเดลมันเรียนรู้ข้อมูลที่เหมาะสมกับข้อมูล ส่วน Y_train_data เป็นคำตอบที่ควรจะได้จากการเรียนรู้\n",
    "ensemble_model.fit(X_train_data, y_labelNum_train) \n",
    "\n",
    "# ใช้ข้อมูลทดสอบ X_test_data เพื่อไว้ทำนายผลลัพธ์ที่ได้จากโมเดลนี้ของข้อมูลทดสอบ\n",
    "y_pred = ensemble_model.predict(X_test_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6555965559655597\n",
      "Confusion Matrix:  [[163   1   4   5   2   6  18]\n",
      " [  8  39   0   2   3   0  15]\n",
      " [ 12   0  33   0   2   3  25]\n",
      " [ 41   0   2  15   3   3  10]\n",
      " [ 13   5   3   1  56   0  24]\n",
      " [ 16   1   2   1   3  74   9]\n",
      " [ 25   2   0   2   6   2 153]]\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_labelNum_test, y_pred)\n",
    "confusionMatrix = confusion_matrix(y_labelNum_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion Matrix: \", confusionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# เขียน model_genhog.pkl ขึ้นมา\n",
    "path_model = 'model_genhog.pkl'\n",
    "pickle.dump(ensemble_model, open(path_model, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
